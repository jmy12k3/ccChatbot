[strings]
# Preprocessing related
resource_path = preprocessing/resource.conv
seq_path = preprocessing/seq.data

# Callbacks related
log_dir = logs
model_dir = model

[ints]
# Hyperparameters
num_layers = 6
d_model = 512
dff = 2048
num_heads = 8

# Tokenizers related
max_length = 20
vocab_size = 10000

# Training related
batch_size = 64
epoch = 20

[floats]
# Hyperparameter
dropout_rate = 0.1