[strings]
log_dir = log_dir
model_data = model_data

resource_data = train_data/xiaohuangji50w.conv
seq_data = train_data/seq.data

input_vocab_path = train_data/inp.vocab
target_vocab_path = train_data/tar.vocab

[ints]
# BERT: 12, 768, 768, 12
# Paper: 6, 512, 2048, 8
# https://arxiv.org/abs/1706.03762
# TF Doc: 4, 128, 512, 8
num_layers = 4
d_model = 128
dff = 512
num_heads = 8

epochs = 10
batch_size = 64

max_length = 25
input_vocab_size = 10000
target_vocab_size = 10000

[floats]
dropout_rate = 0.1